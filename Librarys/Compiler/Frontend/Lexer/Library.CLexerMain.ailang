// Copyright (c) 2025 Sean Collins, 2 Paws Machine and Engineering. All rights reserved.
//
// Licensed under the Sean Collins Software License (SCSL). See the LICENSE file in the root directory of this project
// for the full terms and conditions, including restrictions on forking, corporate use, and permissions for private/teaching purposes.


// Copyright (c) 2025 Sean Collins, 2 Paws Machine and Engineering. All rights reserved.
//
// Licensed under the Sean Collins Software License (SCSL). See the LICENSE file in the root directory of this project
// for the full terms and conditions, including restrictions on forking, corporate use, and permissions for private/teaching purposes.


// Library.CLexerMain.ailang
// Main tokenization loop for the AILang self-hosting compiler

LibraryImport.Compiler.Frontend.Lexer.CLexerTypes
LibraryImport.Compiler.Frontend.Lexer.CLexerCore
LibraryImport.Compiler.Frontend.Lexer.CLexerKeywords
LibraryImport.Compiler.Frontend.Lexer.CLexerStrings
LibraryImport.Compiler.Frontend.Lexer.CLexerNumbers
LibraryImport.Compiler.Frontend.Lexer.CLexerOperators
LibraryImport.Compiler.Frontend.Lexer.CLexerIdentifiers

// =============================================================================
// MAIN TOKENIZATION LOOP
// =============================================================================
Function.Lex_Tokenize {
    Output: Integer
    Body: {
        done = 0
        
        WhileLoop EqualTo(done, 0) {
            Lex_SkipWhitespace()
            
            line_start = Lex.line
            col_start = Lex.col
            
            c = Lex_CurrentChar()
            
            // ─────────────────────────────────────────
            // End of source - emit EOF and exit
            // ─────────────────────────────────────────
            IfCondition EqualTo(c, 0) ThenBlock: {
                Lex_AddToken(Token.EOF, 0, line_start, col_start, 0)
                done = 1
                ContinueLoop
            }
            
            // ─────────────────────────────────────────
            // Newline
            // ─────────────────────────────────────────
            IfCondition EqualTo(c, ASCII.LF) ThenBlock: {
                Lex_AddToken(Token.NEWLINE, 0, line_start, col_start, 1)
                Lex_Advance()
                ContinueLoop
            }
            
            // ─────────────────────────────────────────
            // Comment (// or //DOC: etc)
            // ─────────────────────────────────────────
            IfCondition EqualTo(c, ASCII.SLASH) ThenBlock: {
                next = Lex_PeekChar(1)
                IfCondition EqualTo(next, ASCII.SLASH) ThenBlock: {
                    Lex_TokenizeComment(line_start, col_start)
                    ContinueLoop
                }
            }
            
            // ─────────────────────────────────────────
            // String literal
            // ─────────────────────────────────────────
            IfCondition EqualTo(c, ASCII.DQUOTE) ThenBlock: {
                Lex_TokenizeString(line_start, col_start)
                IfCondition NotEqual(Lex.error, 0) ThenBlock: {
                    ReturnValue(-1)
                }
                ContinueLoop
            }
            
            // ─────────────────────────────────────────
            // Number (digit or negative number)
            // ─────────────────────────────────────────
            is_digit = Lex_IsDigit(c)
            IfCondition EqualTo(is_digit, 1) ThenBlock: {
                Lex_TokenizeNumber(line_start, col_start)
                IfCondition NotEqual(Lex.error, 0) ThenBlock: {
                    ReturnValue(-1)
                }
                ContinueLoop
            }
            
            // Check for negative number (dash followed by digit)
            IfCondition EqualTo(c, ASCII.DASH) ThenBlock: {
                next = Lex_PeekChar(1)
                next_is_digit = Lex_IsDigit(next)
                IfCondition EqualTo(next_is_digit, 1) ThenBlock: {
                    Lex_TokenizeNumber(line_start, col_start)
                    IfCondition NotEqual(Lex.error, 0) ThenBlock: {
                        ReturnValue(-1)
                    }
                    ContinueLoop
                }
            }
            
            // ─────────────────────────────────────────
            // Identifier or keyword
            // ─────────────────────────────────────────
            is_ident_start = Lex_IsIdentifierStart(c)
            IfCondition EqualTo(is_ident_start, 1) ThenBlock: {
                Lex_TokenizeIdentifier(line_start, col_start)
                ContinueLoop
            }
            
            // ─────────────────────────────────────────
            // Operators and delimiters (catch-all)
            // ─────────────────────────────────────────
            handled = Lex_TokenizeOperator(line_start, col_start)
            IfCondition EqualTo(handled, 1) ThenBlock: {
                ContinueLoop
            }
            
            // ─────────────────────────────────────────
            // Unknown character - error
            // ─────────────────────────────────────────
            Lex_Error("Unknown character")
            ReturnValue(-1)
        }
        
        ReturnValue(Lex.token_count)
    }
}

// =============================================================================
// TOKENIZE NUMBER (wrapper)
// Creates NUMBER token from current position
// =============================================================================
Function.Lex_TokenizeNumber {
    Input: line_start: Integer
    Input: col_start: Integer
    Body: {
        value = Lex_ReadNumber()
        
        IfCondition EqualTo(Lex.error, 0) ThenBlock: {
            len = StringLength(value)
            Lex_AddToken(Token.NUMBER, value, line_start, col_start, len)
        }
    }
}

// =============================================================================
// GET TOKEN COUNT
// =============================================================================
Function.Lex_GetTokenCount {
    Output: Integer
    Body: {
        ReturnValue(Lex.token_count)
    }
}

// =============================================================================
// DUMP TOKENS (Debug)
// Prints all tokens for debugging
// =============================================================================
Function.Lex_DumpTokens {
    Body: {
        PrintMessage("=== TOKENS ===\n")
        
        i = 0
        WhileLoop LessThan(i, Lex.token_count) {
            tok = Lex_GetToken(i)
            
            tok_type = ArrayGet(tok, TokField.TYPE)
            tok_value = ArrayGet(tok, TokField.VALUE)
            tok_line = ArrayGet(tok, TokField.LINE)
            tok_col = ArrayGet(tok, TokField.COL)
            
            PrintMessage("[")
            PrintNumber(i)
            PrintMessage("] Type=")
            PrintNumber(tok_type)
            PrintMessage(" Line=")
            PrintNumber(tok_line)
            PrintMessage(" Col=")
            PrintNumber(tok_col)
            
            IfCondition NotEqual(tok_value, 0) ThenBlock: {
                PrintMessage(" Value=\"")
                PrintString(tok_value)
                PrintMessage("\"")
            }
            
            PrintMessage("\n")
            
            i = Add(i, 1)
        }
        
        PrintMessage("=== END TOKENS ===\n")
    }
}